# =====================================
# Streamlit App: ææˆè¡¨å¤šsheetè‡ªåŠ¨å®¡æ ¸ï¼ˆæ€» + è½»å¡ + é‡å¡ï¼‰
# æ ‡çº¢é”™è¯¯æ ¼ + æ ‡é»„åˆåŒå· + ç²¾ç®€é”™è¯¯ä¸‹è½½ + ç‹¬ç«‹é”™è¯¯æ•°ç»Ÿè®¡
# =====================================
import streamlit as st
import pandas as pd
from io import BytesIO
import unicodedata, re

try:
    from openpyxl import Workbook
    from openpyxl.styles import PatternFill
except ImportError:
    st.error("âŒ openpyxl æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œ pip install openpyxl")
    st.stop()

st.title("ğŸ“Š ææˆè¡¨å¤šsheetè‡ªåŠ¨å®¡æ ¸å·¥å…·ï¼ˆæ€» + è½»å¡ + é‡å¡ï¼‰")

# ========== ä¸Šä¼ æ–‡ä»¶ ==========
uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ åŒ…å«â€œææˆâ€ã€â€œæ”¾æ¬¾æ˜ç»†â€ã€â€œäºŒæ¬¡æ˜ç»†â€å’Œâ€œåŸè¡¨â€çš„xlsxæ–‡ä»¶",
    type="xlsx", accept_multiple_files=True
)

if not uploaded_files or len(uploaded_files) < 4:
    st.warning("âš ï¸ è¯·è‡³å°‘ä¸Šä¼  ææˆè¡¨ã€æ”¾æ¬¾æ˜ç»†ã€äºŒæ¬¡æ˜ç»†ã€åŸè¡¨ å››ä¸ªæ–‡ä»¶")
    st.stop()

# ========== å·¥å…·å‡½æ•° ==========
def find_file(files_list, keyword):
    for f in files_list:
        if keyword in f.name:
            return f
    return None

def normalize_text(val):
    if pd.isna(val):
        return ""
    s = str(val)
    s = re.sub(r'[\n\r\t ]+', '', s)
    s = s.replace('\u3000', '')
    return ''.join(unicodedata.normalize('NFKC', ch) for ch in s).lower().strip()

def normalize_num(val):
    if pd.isna(val):
        return None
    s = str(val).replace(",", "").replace("%", "").strip()
    if s in ["", "-", "nan"]:
        return None
    try:
        return float(s)
    except:
        return None

def find_col(df_like, keyword, exact=False):
    key = keyword.strip().lower()
    columns = df_like.columns if hasattr(df_like, "columns") else df_like.index
    for col in columns:
        cname = str(col).strip().lower()
        if (exact and cname == key) or (not exact and key in cname):
            return col
    return None

# ========== è¯»å–æ–‡ä»¶ ==========
tc_file = find_file(uploaded_files, "ææˆ")
fk_file = find_file(uploaded_files, "æ”¾æ¬¾æ˜ç»†")
ec_file = find_file(uploaded_files, "äºŒæ¬¡æ˜ç»†")
original_file = find_file(uploaded_files, "åŸè¡¨")

tc_xls = pd.ExcelFile(tc_file)
sheet_total = next((s for s in tc_xls.sheet_names if "æ€»" in s), None)
sheets_qk = [s for s in tc_xls.sheet_names if "è½»å¡" in s]
sheets_zk = [s for s in tc_xls.sheet_names if "é‡å¡" in s]

tc_sheets = {
    "æ€»": [pd.read_excel(tc_file, sheet_name=sheet_total)] if sheet_total else [],
    "è½»å¡": [pd.read_excel(tc_file, sheet_name=s) for s in sheets_qk],
    "é‡å¡": [pd.read_excel(tc_file, sheet_name=s) for s in sheets_zk],
}

fk_xls = pd.ExcelFile(fk_file)
fk_dfs = [pd.read_excel(fk_file, sheet_name=s) for s in fk_xls.sheet_names if "æ½®æ£" in s]

ec_xls = pd.ExcelFile(ec_file)
ec_df = pd.concat([pd.read_excel(ec_file, sheet_name=s) for s in ec_xls.sheet_names], ignore_index=True)

original_df = pd.read_excel(original_file)

st.success(f"âœ… ææˆè¡¨å·²è¯»å–ï¼šæ€»({len(tc_sheets['æ€»'])})ã€è½»å¡({len(tc_sheets['è½»å¡'])})ã€é‡å¡({len(tc_sheets['é‡å¡'])})")

# ========== å®šä¹‰æ˜ å°„ ==========
MAPPING = {
    "æ”¾æ¬¾æ—¥æœŸ": ("æ”¾æ¬¾æ˜ç»†", "æ”¾æ¬¾æ—¥æœŸ", 0, 1),
    "ææŠ¥äººå‘˜": ("æ”¾æ¬¾æ˜ç»†", "ææŠ¥äººå‘˜", 0, 1),
    "åŸå¸‚ç»ç†": ("æ”¾æ¬¾æ˜ç»†", "åŸå¸‚ç»ç†", 0, 1),
    "ç§Ÿèµæœ¬é‡‘": ("æ”¾æ¬¾æ˜ç»†", "ç§Ÿèµæœ¬é‡‘", 0, 1),
    "æ”¶ç›Šç‡": ("æ”¾æ¬¾æ˜ç»†", "xirr", 0.005, 1),
    "æœŸé™": ("æ”¾æ¬¾æ˜ç»†", "ç§ŸèµæœŸé™/å¹´", 0.5, 12),
    "å®¶è®¿": ("æ”¾æ¬¾æ˜ç»†", "å®¶è®¿", 0, 1),
    "äººå‘˜ç±»å‹": ("æ”¾æ¬¾æ˜ç»†", "ç±»å‹", 0, 1),
    "äºŒæ¬¡äº¤æ¥": ("äºŒæ¬¡æ˜ç»†", "å‡ºæœ¬æµç¨‹æ—¶é—´", 0, 1),
}

# ========== æ¯”å¯¹å‡½æ•° ==========
def get_ref_row(contract_no, source_type):
    contract_no = str(contract_no).strip()
    if source_type == "æ”¾æ¬¾æ˜ç»†":
        for df in fk_dfs:
            col = find_col(df, "åˆåŒ")
            if col is None:
                continue
            res = df[df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    elif source_type == "äºŒæ¬¡æ˜ç»†":
        col = find_col(ec_df, "åˆåŒ")
        if col is not None:
            res = ec_df[ec_df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    elif source_type == "åŸè¡¨":
        col = find_col(original_df, "åˆåŒ", exact=False)
        if col is not None:
            res = original_df[original_df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    return None


# ========== æ ¸å¿ƒå®¡æ ¸å‡½æ•° ==========
def audit_one_sheet(tc_df, sheet_label):
    contract_col_main = find_col(tc_df, "åˆåŒ")
    if not contract_col_main:
        st.warning(f"âš ï¸ {sheet_label}ï¼šæœªæ‰¾åˆ°â€˜åˆåŒâ€™åˆ—ï¼Œè·³è¿‡ã€‚")
        return None, None, 0, 0

    wb = Workbook()
    ws = wb.active
    for i, col_name in enumerate(tc_df.columns, start=1):
        ws.cell(1, i, col_name)

    red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    total_errors = 0
    error_rows = set()
    n = len(tc_df)

    progress = st.progress(0)
    status = st.empty()
    person_type_col = find_col(tc_df, "äººå‘˜ç±»å‹", exact=True)

    for idx, row in tc_df.iterrows():
        contract_no = row.get(contract_col_main)
        if pd.isna(contract_no):
            continue

        row_has_error = False

        for main_kw, (src, ref_kw, tol, mult) in MAPPING.items():
            exact_main = "æœŸé™" in main_kw or main_kw == "äººå‘˜ç±»å‹"
            main_col = find_col(tc_df, main_kw, exact=exact_main)
            if not main_col:
                continue

            if main_kw == "æ”¶ç›Šç‡":
                person_type = str(row.get(person_type_col, "")).strip()
                if person_type == "è½»å¡":
                    ref_row = get_ref_row(contract_no, "åŸè¡¨")
                    ref_kw = "å¹´åŒ–nim"
                else:
                    ref_row = get_ref_row(contract_no, src)
            else:
                ref_row = get_ref_row(contract_no, src)

            if ref_row is None:
                continue

            ref_col = find_col(ref_row, ref_kw, exact=(main_kw == "äººå‘˜ç±»å‹"))
            if not ref_col:
                continue

            main_val = row[main_col]
            ref_val = ref_row[ref_col]

            if "æ—¥æœŸ" in main_kw or main_kw == "äºŒæ¬¡äº¤æ¥":
                try:
                    main_dt = pd.to_datetime(main_val, errors='coerce').normalize()
                    ref_dt = pd.to_datetime(ref_val, errors='coerce').normalize()
                except:
                    main_dt = ref_dt = pd.NaT
                if pd.isna(main_dt) or pd.isna(ref_dt) or main_dt != ref_dt:
                    row_has_error = True
                    total_errors += 1
                    ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill
            else:
                m = normalize_num(main_val)
                r = normalize_num(ref_val)
                if main_kw == "æ”¶ç›Šç‡" and m is not None and r is not None:
                    if m > 1: m /= 100
                    if r > 1: r /= 100
                if m is not None and r is not None:
                    if "æœŸé™" in main_kw:
                        r *= mult
                    if abs(m - r) > tol:
                        row_has_error = True
                        total_errors += 1
                        ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill
                else:
                    if normalize_text(main_val) != normalize_text(ref_val):
                        row_has_error = True
                        total_errors += 1
                        ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill

        if row_has_error:
            ws.cell(idx + 2, list(tc_df.columns).index(contract_col_main) + 1).fill = yellow_fill
            error_rows.add(idx)

        for j, val in enumerate(row, start=1):
            ws.cell(idx + 2, j, val)

        if (idx + 1) % 10 == 0 or (idx + 1) == n:
            progress.progress((idx + 1) / n)
            status.text(f"{sheet_label} å®¡æ ¸è¿›åº¦ï¼š{idx + 1}/{n}")

    # ===== è¾“å‡ºåŒº =====
    output_full = BytesIO()
    wb.save(output_full)
    output_full.seek(0)

    # ç²¾ç®€é”™è¯¯è¡¨
    wb_err = Workbook()
    ws_err = wb_err.active
    for i, col_name in enumerate(tc_df.columns, start=1):
        ws_err.cell(1, i, col_name)
    row_idx = 2
    for idx in sorted(error_rows):
        for j, val in enumerate(tc_df.iloc[idx], start=1):
            ws_err.cell(row_idx, j, val)
            orig_cell = ws.cell(idx + 2, j)
            fill = orig_cell.fill
            if hasattr(fill, "fill_type") and fill.fill_type == "solid":
                new_fill = PatternFill(fill_type="solid",
                                       start_color=fill.start_color.rgb,
                                       end_color=fill.end_color.rgb)
                ws_err.cell(row_idx, j).fill = new_fill
        row_idx += 1

    output_err = BytesIO()
    wb_err.save(output_err)
    output_err.seek(0)

    return output_full, output_err, total_errors, len(error_rows)

# ========== å®¡æ ¸æ‰€æœ‰ sheet ==========
results = {}
for label, df_list in tc_sheets.items():
    if not df_list:
        continue
    for i, df in enumerate(df_list, start=1):
        tag = f"{label}{i if len(df_list) > 1 else ''}"
        st.divider()
        st.subheader(f"ğŸ“˜ æ­£åœ¨å®¡æ ¸ï¼š{tag}")
        full, err, errs, rows = audit_one_sheet(df, tag)
        results[tag] = (full, err, errs, rows)

# ========== ğŸ” åå‘æ¼å¡«æ£€æŸ¥ï¼ˆä¿æŒä¸å˜ï¼‰ ==========
st.divider()
st.subheader("ğŸ” åå‘æ¼å¡«æ£€æŸ¥ï¼ˆä»…åŸºäºæ”¾æ¬¾æ˜ç»†ä¸­åŒ…å«â€œæ½®æ£â€çš„sheetï¼‰")

def get_contracts_from_df(df):
    col = find_col(df, "åˆåŒ", exact=False)
    if col is not None:
        return set(df[col].dropna().astype(str).str.strip())
    return set()

def get_contracts_from_fk_dfs(fk_list):
    all_cons = set()
    for df in fk_list:
        all_cons |= get_contracts_from_df(df)
    return all_cons

contracts_total = get_contracts_from_df(tc_sheets["æ€»"][0])
contracts_fk = get_contracts_from_fk_dfs(fk_dfs)
missing_contracts = sorted(list(contracts_fk - contracts_total))

if missing_contracts:
    st.warning(f"âš ï¸ å‘ç° {len(missing_contracts)} ä¸ªåˆåŒå·å­˜åœ¨äºæ”¾æ¬¾æ˜ç»†ä¸­ï¼Œä½†æœªå‡ºç°åœ¨ææˆè¡¨â€˜æ€»â€™sheetä¸­")
    df_missing = pd.DataFrame({"æ¼å¡«åˆåŒå·": missing_contracts})
    output_missing = BytesIO()
    with pd.ExcelWriter(output_missing, engine="openpyxl") as writer:
        df_missing.to_excel(writer, index=False, sheet_name="æ¼å¡«åˆåŒå·")
    output_missing.seek(0)
    st.download_button(
        "ğŸ“¥ ä¸‹è½½æ¼å¡«åˆåŒå·è¡¨ï¼ˆåŸºäºæ”¾æ¬¾æ˜ç»†-æ½®æ£ï¼‰",
        data=output_missing,
        file_name="ææˆ_æ¼å¡«åˆåŒå·_åŸºäºæ”¾æ¬¾æ˜ç»†_æ½®æ£.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
else:
    st.success("âœ… æœªå‘ç°æ¼å¡«åˆåŒå·ï¼ˆåŸºäºæ”¾æ¬¾æ˜ç»†-æ½®æ£ï¼‰ã€‚")

# ========== ä¸‹è½½åŒº ==========
st.divider()
st.subheader("ğŸ“¤ ä¸‹è½½å®¡æ ¸ç»“æœæ–‡ä»¶")

for tag, (full, err, errs, rows) in results.items():
    st.write(f"ğŸ“˜ **{tag}**ï¼šå‘ç° {errs} ä¸ªé”™è¯¯ï¼Œå…± {rows} è¡Œå¼‚å¸¸")
    st.download_button(
        f"ğŸ“¥ ä¸‹è½½ {tag} å®¡æ ¸æ ‡æ³¨ç‰ˆ",
        data=full,
        file_name=f"ææˆ_{tag}_å®¡æ ¸æ ‡æ³¨ç‰ˆ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    if rows > 0:
        st.download_button(
            f"ğŸ“¥ ä¸‹è½½ {tag} é”™è¯¯ç²¾ç®€ç‰ˆï¼ˆå«çº¢é»„æ ‡è®°ï¼‰",
            data=err,
            file_name=f"ææˆ_{tag}_é”™è¯¯ç²¾ç®€ç‰ˆ.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

st.success("âœ… æ‰€æœ‰sheetå®¡æ ¸å®Œæˆï¼")
