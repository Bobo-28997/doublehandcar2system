# =====================================
# Streamlit App: ææˆè¡¨æ€»sheetè‡ªåŠ¨å®¡æ ¸ï¼ˆæ ‡çº¢é”™è¯¯æ ¼ + æ ‡é»„åˆåŒå· + ç²¾ç®€é”™è¯¯ä¸‹è½½ï¼‰
# ä¿®å¤ï¼šå¤åˆ¶é¢œè‰²æ—¶ä¸ºç›®æ ‡å·¥ä½œç°¿åˆ›å»ºæ–°çš„ PatternFillï¼ˆé¿å…è·¨å·¥ä½œç°¿å¤ç”¨æ ·å¼å¯¹è±¡ï¼‰
# =====================================
import streamlit as st
import pandas as pd
from io import BytesIO
import unicodedata, re

try:
    from openpyxl import Workbook
    from openpyxl.styles import PatternFill
except ImportError:
    st.error("âŒ openpyxl æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œ pip install openpyxl")
    st.stop()

st.title("ğŸ“Š ææˆè¡¨ã€æ€»ã€sheet è‡ªåŠ¨å®¡æ ¸å·¥å…·ï¼ˆæ ‡çº¢é”™è¯¯æ ¼ + æ ‡é»„åˆåŒå· + ç²¾ç®€é”™è¯¯ä¸‹è½½ï¼‰")

# ========== ä¸Šä¼ æ–‡ä»¶ ==========
uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ åŒ…å«â€œææˆâ€ã€â€œæ”¾æ¬¾æ˜ç»†â€ã€â€œäºŒæ¬¡æ˜ç»†â€å’Œâ€œåŸè¡¨â€çš„xlsxæ–‡ä»¶",
    type="xlsx", accept_multiple_files=True
)

if not uploaded_files or len(uploaded_files) < 4:
    st.warning("âš ï¸ è¯·è‡³å°‘ä¸Šä¼  ææˆè¡¨ã€æ”¾æ¬¾æ˜ç»†ã€äºŒæ¬¡æ˜ç»†ã€åŸè¡¨ å››ä¸ªæ–‡ä»¶")
    st.stop()

# ========== å·¥å…·å‡½æ•° ==========
def find_file(files_list, keyword):
    for f in files_list:
        if keyword in f.name:
            return f
    return None

def normalize_text(val):
    if pd.isna(val):
        return ""
    s = str(val)
    s = re.sub(r'[\n\r\t ]+', '', s)
    s = s.replace('\u3000', '')
    return ''.join(unicodedata.normalize('NFKC', ch) for ch in s).lower().strip()

def normalize_num(val):
    if pd.isna(val):
        return None
    s = str(val).replace(",", "").replace("%", "").strip()
    if s in ["", "-", "nan"]:
        return None
    try:
        return float(s)
    except:
        return None

def find_col(df_like, keyword, exact=False):
    key = keyword.strip().lower()
    columns = df_like.columns if hasattr(df_like, "columns") else df_like.index
    for col in columns:
        cname = str(col).strip().lower()
        if (exact and cname == key) or (not exact and key in cname):
            return col
    return None

# ========== è¯»å–æ–‡ä»¶ ==========
tc_file = find_file(uploaded_files, "ææˆ")
fk_file = find_file(uploaded_files, "æ”¾æ¬¾æ˜ç»†")
ec_file = find_file(uploaded_files, "äºŒæ¬¡æ˜ç»†")
original_file = find_file(uploaded_files, "åŸè¡¨")

tc_xls = pd.ExcelFile(tc_file)
sheet_total = next((s for s in tc_xls.sheet_names if "æ€»" in s), None)
tc_df = pd.read_excel(tc_file, sheet_name=sheet_total)

fk_xls = pd.ExcelFile(fk_file)
fk_dfs = [pd.read_excel(fk_file, sheet_name=s) for s in fk_xls.sheet_names if "æ½®æ£" in s]

ec_xls = pd.ExcelFile(ec_file)
ec_df = pd.concat([pd.read_excel(ec_file, sheet_name=s) for s in ec_xls.sheet_names], ignore_index=True)

original_xls = pd.ExcelFile(original_file)
original_df = pd.read_excel(original_xls)

st.success("âœ… æ–‡ä»¶è¯»å–å®Œæˆ")

# ========== å®šä¹‰æ˜ å°„ ==========
MAPPING = {
    "æ”¾æ¬¾æ—¥æœŸ": ("æ”¾æ¬¾æ˜ç»†", "æ”¾æ¬¾æ—¥æœŸ", 0, 1),
    "ææŠ¥äººå‘˜": ("æ”¾æ¬¾æ˜ç»†", "ææŠ¥äººå‘˜", 0, 1),
    "åŸå¸‚ç»ç†": ("æ”¾æ¬¾æ˜ç»†", "åŸå¸‚ç»ç†", 0, 1),
    "ç§Ÿèµæœ¬é‡‘": ("æ”¾æ¬¾æ˜ç»†", "ç§Ÿèµæœ¬é‡‘", 0, 1),
    "æ”¶ç›Šç‡": ("æ”¾æ¬¾æ˜ç»†", "xirr", 0.005, 1),
    "æœŸé™": ("æ”¾æ¬¾æ˜ç»†", "ç§ŸèµæœŸé™/å¹´", 0.5, 12),
    "å®¶è®¿": ("æ”¾æ¬¾æ˜ç»†", "å®¶è®¿", 0, 1),
    "äººå‘˜ç±»å‹": ("æ”¾æ¬¾æ˜ç»†", "ç±»å‹", 0, 1),
    "äºŒæ¬¡äº¤æ¥": ("äºŒæ¬¡æ˜ç»†", "å‡ºæœ¬æµç¨‹æ—¶é—´", 0, 1),
}

contract_col_main = find_col(tc_df, "åˆåŒ")

# ========== æ¯”å¯¹è¾…åŠ©å‡½æ•° ==========
def get_ref_row(contract_no, source_type):
    contract_no = str(contract_no).strip()
    if source_type == "æ”¾æ¬¾æ˜ç»†":
        for df in fk_dfs:
            col = find_col(df, "åˆåŒ")
            if col is None:
                continue
            res = df[df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    elif source_type == "äºŒæ¬¡æ˜ç»†":
        col = find_col(ec_df, "åˆåŒ")
        if col is not None:
            res = ec_df[ec_df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    elif source_type == "åŸè¡¨":
        col = find_col(original_df, "åˆåŒ", exact=False)
        if col is not None:
            res = original_df[original_df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    return None

# ========== æ‰§è¡Œå®¡æ ¸ ==========
wb = Workbook()
ws = wb.active
for i, col_name in enumerate(tc_df.columns, start=1):
    ws.cell(1, i, col_name)

red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

total_errors = 0
error_rows = set()

progress = st.progress(0)
status = st.empty()

person_type_col = find_col(tc_df, "äººå‘˜ç±»å‹", exact=True)
n = len(tc_df)

for idx, row in tc_df.iterrows():
    contract_no = row.get(contract_col_main)
    if pd.isna(contract_no):
        continue

    row_has_error = False

    for main_kw, (src, ref_kw, tol, mult) in MAPPING.items():
        exact_main = "æœŸé™" in main_kw or main_kw == "äººå‘˜ç±»å‹"
        main_col = find_col(tc_df, main_kw, exact=exact_main)
        if not main_col:
            continue

        if main_kw == "æ”¶ç›Šç‡":
            person_type = str(row[person_type_col]).strip()
            if person_type == "è½»å¡":
                ref_row = get_ref_row(contract_no, "åŸè¡¨")
                ref_kw = "å¹´åŒ–NIM"
            else:
                ref_row = get_ref_row(contract_no, src)
        else:
            ref_row = get_ref_row(contract_no, src)

        if ref_row is None:
            continue

        ref_col = find_col(ref_row, ref_kw, exact=(main_kw == "äººå‘˜ç±»å‹"))
        if not ref_col:
            continue

        main_val = row[main_col]
        ref_val = ref_row[ref_col]

        if "æ—¥æœŸ" in main_kw or main_kw == "äºŒæ¬¡äº¤æ¥":
            try:
                main_dt = pd.to_datetime(main_val, errors='coerce').normalize()
                ref_dt = pd.to_datetime(ref_val, errors='coerce').normalize()
            except:
                main_dt = ref_dt = pd.NaT
            if pd.isna(main_dt) or pd.isna(ref_dt) or main_dt != ref_dt:
                row_has_error = True
                total_errors += 1
                ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill
        else:
            m = normalize_num(main_val)
            r = normalize_num(ref_val)
            if main_kw == "æ”¶ç›Šç‡" and m is not None and r is not None:
                if m > 1: m /= 100
                if r > 1: r /= 100
            if m is not None and r is not None:
                if "æœŸé™" in main_kw:
                    r *= mult
                if abs(m - r) > tol:
                    row_has_error = True
                    total_errors += 1
                    ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill
            else:
                if normalize_text(main_val) != normalize_text(ref_val):
                    row_has_error = True
                    total_errors += 1
                    ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill

    # æ ‡é»„åˆåŒå·
    if row_has_error:
        ws.cell(idx + 2, list(tc_df.columns).index(contract_col_main) + 1).fill = yellow_fill
        error_rows.add(idx)

    for j, val in enumerate(row, start=1):
        ws.cell(idx + 2, j, val)

    if (idx + 1) % 10 == 0 or (idx + 1) == n:
        progress.progress((idx + 1) / n)
        status.text(f"å®¡æ ¸è¿›åº¦ï¼š{idx + 1}/{n}")

# ========== è¾“å‡ºç»“æœï¼ˆå«ä¿®å¤ï¼šå®‰å…¨å¤åˆ¶æ ·å¼ï¼‰ ==========
# æ³¨æ„ï¼šåªæœ‰åœ¨è¿™é‡Œâ€”â€”æ‰€æœ‰å·¥ä½œç°¿å·²å†™å…¥å®Œæˆä¹‹åâ€”â€”æ‰åˆ›å»º BytesIO å¹¶å‡†å¤‡ä¸‹è½½å†…å®¹

# å…ˆæŠŠå®Œæ•´å¸¦æ ‡æ³¨çš„å·¥ä½œç°¿ä¿å­˜åˆ°å†…å­˜
output_full = BytesIO()
wb.save(output_full)
output_full.seek(0)

# ç”Ÿæˆç²¾ç®€é”™è¯¯è¡¨ï¼šå¤åˆ¶å€¼å¹¶ä¸ºæœ‰é¢œè‰²çš„å•å…ƒæ ¼åœ¨æ–°å·¥ä½œç°¿ç”¨æ–° PatternFill é‡å»ºé¢œè‰²
wb_error = Workbook()
ws_err = wb_error.active
for i, col_name in enumerate(tc_df.columns, start=1):
    ws_err.cell(1, i, col_name)

row_idx = 2
for idx in sorted(error_rows):
    for j, val in enumerate(tc_df.iloc[idx], start=1):
        # å†™å€¼
        ws_err.cell(row_idx, j, val)
        # ä»ä¸»å·¥ä½œè¡¨è¯»å–åŸå§‹å•å…ƒæ ¼ï¼ˆæ³¨æ„ï¼šws æ˜¯åŸå·¥ä½œç°¿çš„sheetï¼‰
        try:
            orig_cell = ws.cell(idx + 2, j)
            fill = orig_cell.fill
            if hasattr(fill, "fill_type") and fill.fill_type not in (None, "none", ""):
                # å°è¯•å–å‡º start_color / end_color çš„ rgb æˆ– index
                start = getattr(fill.start_color, "rgb", None) or getattr(fill.start_color, "index", None)
                end = getattr(fill.end_color, "rgb", None) or getattr(fill.end_color, "index", None)
                if start or end:
                    new_fill = PatternFill(fill_type=fill.fill_type, start_color=start, end_color=end)
                    ws_err.cell(row_idx, j).fill = new_fill
        except Exception:
            # å®¹é”™ï¼šè‹¥è¯»å–åŸå•å…ƒæ ¼æˆ–å¤åˆ¶æ ·å¼å¤±è´¥ï¼Œåªä¿ç•™å€¼ï¼Œä¸é˜»æ–­æµç¨‹
            pass
    row_idx += 1

output_err = BytesIO()
wb_error.save(output_err)
output_err.seek(0)

# ========== ğŸ” åå‘æ¼å¡«æ£€æŸ¥ï¼ˆä»…ä½¿ç”¨æ”¾æ¬¾æ˜ç»†ä¸­åŒ…å«â€œæ½®æ£â€çš„sheetï¼‰ ==========
st.divider()
st.subheader("ğŸ” åå‘æ¼å¡«æ£€æŸ¥ï¼ˆä»…åŸºäºæ”¾æ¬¾æ˜ç»†ä¸­åŒ…å«â€œæ½®æ£â€çš„sheetï¼‰")

def get_contracts_from_df(df):
    col = find_col(df, "åˆåŒ", exact=False)
    if col is not None:
        return set(df[col].dropna().astype(str).str.strip())
    return set()

def get_contracts_from_fk_dfs(fk_list):
    all_cons = set()
    for df in fk_list:
        all_cons |= get_contracts_from_df(df)
    return all_cons

contracts_total = get_contracts_from_df(tc_df)
# åªä½¿ç”¨ fk_dfsï¼ˆä½ ä¹‹å‰åªè¯»å–äº†åŒ…å«â€œæ½®æ£â€çš„ sheetsï¼‰
contracts_fk = get_contracts_from_fk_dfs(fk_dfs)

# åªå¯¹æ”¾æ¬¾æ˜ç»†ï¼ˆæ½®æ£ sheetsï¼‰ä¸­çš„åˆåŒå·è¿›è¡Œåå‘æ£€æŸ¥
missing_contracts = sorted(list(contracts_fk - contracts_total))

if missing_contracts:
    st.warning(f"âš ï¸ å‘ç° {len(missing_contracts)} ä¸ªåˆåŒå·å­˜åœ¨äºæ”¾æ¬¾æ˜ç»†ï¼ˆå«â€œæ½®æ£â€çš„sheetï¼‰ä¸­ï¼Œä½†æœªå‡ºç°åœ¨ææˆè¡¨çš„â€˜æ€»â€™sheetä¸­")
    df_missing = pd.DataFrame({"æ¼å¡«åˆåŒå·": missing_contracts})
    output_missing = BytesIO()
    with pd.ExcelWriter(output_missing, engine="openpyxl") as writer:
        df_missing.to_excel(writer, index=False, sheet_name="æ¼å¡«åˆåŒå·")
    output_missing.seek(0)
    st.download_button(
        "ğŸ“¥ ä¸‹è½½æ¼å¡«åˆåŒå·è¡¨ï¼ˆåŸºäºæ”¾æ¬¾æ˜ç»†-æ½®æ£ï¼‰",
        data=output_missing,
        file_name="ææˆ_æ¼å¡«åˆåŒå·_åŸºäºæ”¾æ¬¾æ˜ç»†_æ½®æ£.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
else:
    st.success("âœ… æœªå‘ç°æ¼å¡«åˆåŒå·ï¼ˆåŸºäºæ”¾æ¬¾æ˜ç»†-æ½®æ£ï¼‰ã€‚")

# ========== ä¸‹è½½åŒº ==========
st.divider()
st.subheader("ğŸ“¤ ä¸‹è½½å®¡æ ¸ç»“æœæ–‡ä»¶")

# ä»…å½“æµéç©ºæ—¶æ‰æ˜¾ç¤ºä¸‹è½½æŒ‰é’®ï¼ˆé˜²æ­¢æå‰åˆ›å»ºæˆ–å˜é‡æœªå®šä¹‰ï¼‰
if output_full is not None:
    st.download_button(
        "ğŸ“¥ ä¸‹è½½ææˆæ€»sheetå®¡æ ¸æ ‡æ³¨ç‰ˆ",
        data=output_full,
        file_name="ææˆ_æ€»sheet_å®¡æ ¸æ ‡æ³¨ç‰ˆ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

if error_rows and output_err is not None:
    st.download_button(
        "ğŸ“¥ ä¸‹è½½ä»…é”™è¯¯ä¸æ ‡é»„åˆåŒå·ç²¾ç®€ç‰ˆï¼ˆå«çº¢é»„æ ‡è®°ï¼‰",
        data=output_err,
        file_name="ææˆ_é”™è¯¯ç²¾ç®€ç‰ˆ_å¸¦é¢œè‰².xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

st.success(f"âœ… å®¡æ ¸å®Œæˆï¼Œå…±å‘ç° {total_errors} å¤„é”™è¯¯ï¼Œ{len(error_rows)} è¡ŒåˆåŒæ¶‰åŠå¼‚å¸¸")
