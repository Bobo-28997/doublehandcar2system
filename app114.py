# =====================================
# Streamlit App: ææˆè¡¨æ€»sheetè‡ªåŠ¨å®¡æ ¸ï¼ˆæ ‡çº¢é”™è¯¯æ ¼ + æ ‡é»„åˆåŒå·ï¼‰
# =====================================
import streamlit as st
import pandas as pd
from io import BytesIO
import unicodedata, re

# å®‰å…¨å¯¼å…¥ openpyxl
try:
    from openpyxl import Workbook
    from openpyxl.styles import PatternFill
except ImportError:
    st.error("âŒ openpyxl æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œ pip install openpyxl")
    st.stop()

# -------------------------------
# é¡µé¢æ ‡é¢˜
# -------------------------------
st.title("ğŸ“Š ææˆè¡¨ã€æ€»ã€sheet è‡ªåŠ¨å®¡æ ¸å·¥å…·ï¼ˆæ ‡çº¢é”™è¯¯æ ¼ + æ ‡é»„åˆåŒå·ï¼‰")

# =====================================
# ä¸€ã€ä¸Šä¼ æ–‡ä»¶
# =====================================
uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ åŒ…å«â€œææˆâ€ã€â€œæ”¾æ¬¾æ˜ç»†â€ã€â€œäºŒæ¬¡æ˜ç»†â€å’Œâ€œåŸè¡¨â€çš„xlsxæ–‡ä»¶",
    type="xlsx", accept_multiple_files=True
)

if not uploaded_files or len(uploaded_files) < 4:
    st.warning("âš ï¸ è¯·è‡³å°‘ä¸Šä¼  ææˆè¡¨ã€æ”¾æ¬¾æ˜ç»†ã€äºŒæ¬¡æ˜ç»†ã€åŸè¡¨ å››ä¸ªæ–‡ä»¶")
    st.stop()
else:
    st.success("âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ")

# =====================================
# äºŒã€å·¥å…·å‡½æ•°
# =====================================
def find_file(files_list, keyword):
    for f in files_list:
        if keyword in f.name:
            return f
    return None

def normalize_text(val):
    if pd.isna(val):
        return ""
    s = str(val)
    s = re.sub(r'[\n\r\t ]+', '', s)
    s = s.replace('\u3000', '')
    return ''.join(unicodedata.normalize('NFKC', ch) for ch in s).lower().strip()

def normalize_num(val):
    if pd.isna(val):
        return None
    s = str(val).replace(",", "").replace("%", "").strip()
    if s in ["", "-", "nan"]:
        return None
    try:
        return float(s)
    except:
        return None

def find_col(df_like, keyword, exact=False):
    """åœ¨DataFrameä¸­æŸ¥æ‰¾åŒ…å«å…³é”®å­—çš„åˆ—"""
    key = keyword.strip().lower()
    columns = df_like.columns if hasattr(df_like, "columns") else df_like.index
    for col in columns:
        cname = str(col).strip().lower()
        if (exact and cname == key) or (not exact and key in cname):
            return col
    return None

# =====================================
# ä¸‰ã€è¯»å–æ–‡ä»¶
# =====================================
tc_file = find_file(uploaded_files, "ææˆ")
fk_file = find_file(uploaded_files, "æ”¾æ¬¾æ˜ç»†")
ec_file = find_file(uploaded_files, "äºŒæ¬¡æ˜ç»†")
original_file = find_file(uploaded_files, "åŸè¡¨")

if not (tc_file and fk_file and ec_file and original_file):
    st.error("âŒ æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·ç¡®ä¿æ–‡ä»¶åä¸­åŒ…å« ææˆã€æ”¾æ¬¾æ˜ç»†ã€äºŒæ¬¡æ˜ç»†ã€åŸè¡¨")
    st.stop()

# ææˆè¡¨ï¼šè‡ªåŠ¨é€‰æ‹©å«â€œæ€»â€çš„sheet
tc_xls = pd.ExcelFile(tc_file)
sheet_total = next((s for s in tc_xls.sheet_names if "æ€»" in s), None)
if sheet_total is None:
    st.error("âŒ ææˆæ–‡ä»¶ä¸­æœªæ‰¾åˆ°åŒ…å«â€œæ€»â€çš„sheet")
    st.stop()
tc_df = pd.read_excel(tc_file, sheet_name=sheet_total)

# æ”¾æ¬¾æ˜ç»†ï¼šä»…å–åŒ…å«â€œæ½®æ£â€çš„sheet
fk_xls = pd.ExcelFile(fk_file)
fk_sheets = [s for s in fk_xls.sheet_names if "æ½®æ£" in s]
if not fk_sheets:
    st.error("âŒ æ”¾æ¬¾æ˜ç»†æ–‡ä»¶ä¸­æœªæ‰¾åˆ°åŒ…å«â€œæ½®æ£â€çš„sheet")
    st.stop()
fk_dfs = [pd.read_excel(fk_file, sheet_name=s) for s in fk_sheets]

# äºŒæ¬¡æ˜ç»†ï¼šåˆå¹¶æ‰€æœ‰sheet
ec_xls = pd.ExcelFile(ec_file)
ec_df_list = [pd.read_excel(ec_file, sheet_name=s) for s in ec_xls.sheet_names]
ec_df = pd.concat(ec_df_list, ignore_index=True)

original_xls = pd.ExcelFile(original_file)
original_df = pd.read_excel(original_xls)

st.success(f"âœ… æ–‡ä»¶è¯»å–å®Œæˆï¼Œææˆæ€»sheet {len(tc_df)} è¡Œï¼ŒåŸè¡¨ {len(original_df)} è¡Œ")

# =====================================
# å››ã€å­—æ®µæ˜ å°„å®šä¹‰
# =====================================
MAPPING = {
    "æ”¾æ¬¾æ—¥æœŸ": ("æ”¾æ¬¾æ˜ç»†", "æ”¾æ¬¾æ—¥æœŸ", 0, 1),
    "ææŠ¥äººå‘˜": ("æ”¾æ¬¾æ˜ç»†", "ææŠ¥äººå‘˜", 0, 1),
    "åŸå¸‚ç»ç†": ("æ”¾æ¬¾æ˜ç»†", "åŸå¸‚ç»ç†", 0, 1),
    "ç§Ÿèµæœ¬é‡‘": ("æ”¾æ¬¾æ˜ç»†", "ç§Ÿèµæœ¬é‡‘", 0, 1),
    "æ”¶ç›Šç‡": ("æ”¾æ¬¾æ˜ç»†", "xirr", 0.005, 1),
    "æœŸé™": ("æ”¾æ¬¾æ˜ç»†", "ç§ŸèµæœŸé™/å¹´", 0.5, 12),
    "å®¶è®¿": ("æ”¾æ¬¾æ˜ç»†", "å®¶è®¿", 0, 1),
    "äººå‘˜ç±»å‹": ("æ”¾æ¬¾æ˜ç»†", "ç±»å‹", 0, 1),
    "äºŒæ¬¡äº¤æ¥": ("äºŒæ¬¡æ˜ç»†", "å‡ºæœ¬æµç¨‹æ—¶é—´", 0, 1),
}

contract_col_main = find_col(tc_df, "åˆåŒ")
if not contract_col_main:
    st.error("âŒ ææˆæ€»sheet æœªæ‰¾åˆ°åˆåŒå·åˆ—")
    st.stop()

# =====================================
# äº”ã€ä¸»æ¯”å¯¹å‡½æ•°ï¼ˆå«åŸè¡¨æ¨¡ç³ŠåŒ¹é…ï¼‰
# =====================================
def get_ref_row(contract_no, source_type):
    contract_no = str(contract_no).strip()
    if source_type == "æ”¾æ¬¾æ˜ç»†":
        for df in fk_dfs:
            col = find_col(df, "åˆåŒ")
            if col is None:
                continue
            res = df[df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    elif source_type == "äºŒæ¬¡æ˜ç»†":
        col = find_col(ec_df, "åˆåŒ")
        if col is not None:
            res = ec_df[ec_df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    elif source_type == "åŸè¡¨":
        col = find_col(original_df, "åˆåŒ", exact=False)  # æ¨¡ç³ŠåŒ¹é…â€œåˆåŒâ€
        if col is not None:
            res = original_df[original_df[col].astype(str).str.strip() == contract_no]
            if not res.empty:
                return res.iloc[0]
    return None

# =====================================
# å…­ã€æ‰§è¡Œå®¡æ ¸
# =====================================
try:
    wb = Workbook()
except Exception as e:
    st.error(f"âŒ Workbook åˆå§‹åŒ–å¤±è´¥: {e}")
    st.stop()

ws = wb.active
for i, col_name in enumerate(tc_df.columns, start=1):
    ws.cell(1, i, col_name)

red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

total_errors = 0
n = len(tc_df)
progress = st.progress(0)
status = st.empty()

person_type_col = find_col(tc_df, "äººå‘˜ç±»å‹", exact=True)

for idx, row in tc_df.iterrows():
    contract_no = row.get(contract_col_main)
    if pd.isna(contract_no):
        continue

    row_has_error = False

    for main_kw, (src, ref_kw, tol, mult) in MAPPING.items():
        exact_main = "æœŸé™" in main_kw or main_kw == "äººå‘˜ç±»å‹"
        main_col = find_col(tc_df, main_kw, exact=exact_main)
        if not main_col:
            continue

        # åˆ¤æ–­ä½¿ç”¨å“ªä¸ªå‚è€ƒè¡¨
        if main_kw == "æ”¶ç›Šç‡":
            person_type = str(row[person_type_col]).strip()
            if person_type == "è½»å¡":
                ref_row = get_ref_row(contract_no, "åŸè¡¨")
                ref_kw = "å¹´åŒ–NIM"
            else:
                ref_row = get_ref_row(contract_no, src)
        else:
            ref_row = get_ref_row(contract_no, src)

        if ref_row is None:
            continue

        ref_col = find_col(ref_row, ref_kw, exact=(main_kw == "äººå‘˜ç±»å‹"))
        if not ref_col:
            continue

        main_val = row[main_col]
        ref_val = ref_row[ref_col]

        # æ—¥æœŸæ¯”å¯¹
        if "æ—¥æœŸ" in main_kw or main_kw == "äºŒæ¬¡äº¤æ¥":
            try:
                main_dt = pd.to_datetime(main_val, errors='coerce').normalize()
                ref_dt = pd.to_datetime(ref_val, errors='coerce').normalize()
            except:
                main_dt = ref_dt = pd.NaT
            if pd.isna(main_dt) or pd.isna(ref_dt) or main_dt != ref_dt:
                row_has_error = True
                total_errors += 1
                ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill
        else:
            m = normalize_num(main_val)
            r = normalize_num(ref_val)
            if main_kw == "æ”¶ç›Šç‡" and m is not None and r is not None:
                if m > 1: m /= 100
                if r > 1: r /= 100
            if m is not None and r is not None:
                if "æœŸé™" in main_kw:
                    r *= mult
                if abs(m - r) > tol:
                    row_has_error = True
                    total_errors += 1
                    ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill
            else:
                if normalize_text(main_val) != normalize_text(ref_val):
                    row_has_error = True
                    total_errors += 1
                    ws.cell(idx + 2, list(tc_df.columns).index(main_col) + 1).fill = red_fill

    if row_has_error:
        ws.cell(idx + 2, list(tc_df.columns).index(contract_col_main) + 1).fill = yellow_fill

    for j, val in enumerate(row, start=1):
        ws.cell(idx + 2, j, val)

    if (idx + 1) % 10 == 0 or (idx + 1) == n:
        progress.progress((idx + 1) / n)
        status.text(f"å®¡æ ¸è¿›åº¦ï¼š{idx + 1}/{n}")

# =====================================
# ä¸ƒã€è¾“å‡ºç»“æœ
# =====================================
output = BytesIO()
wb.save(output)
output.seek(0)

st.download_button(
    "ğŸ“¥ ä¸‹è½½ææˆæ€»sheetå®¡æ ¸æ ‡æ³¨ç‰ˆ",
    data=output,
    file_name="ææˆ_æ€»sheet_å®¡æ ¸æ ‡æ³¨ç‰ˆ.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

st.success(f"âœ… å®¡æ ¸å®Œæˆï¼Œå…±å‘ç° {total_errors} å¤„é”™è¯¯")
